# Required: API key (use 'ollama' for local Ollama, or an OpenAI key for cloud)
OPENAI_API_KEY=ollama

# Optional: base URL for OpenAI-compatible API (default: Ollama local)
# OPENAI_BASE_URL=http://host.docker.internal:11434/v1

# Optional: model (default: llama3.2:3b)
# OPENAI_MODEL=llama3.2:3b

# Optional: port (default: 3001)
# PORT=3001
